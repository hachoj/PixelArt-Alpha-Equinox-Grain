{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ff5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert image tagging and captioning AI specialized in creating training data for high-fidelity text-to-image models.\n",
    "\n",
    "Your task is to write a comprehensive, dense, and visually descriptive caption for the provided image.\n",
    "\n",
    "**Guidelines:**\n",
    "1.  **Structure:**\n",
    "* **Sentence 1:** Clearly identify the main subject, their action/pose, and the immediate context.\n",
    "* **Sentence 2-3:** Describe the environment, background elements, and spatial relationships (e.g., \"in the foreground,\" \"to the left\").\n",
    "* **Sentence 4:** Describe the artistic medium (e.g., photograph, oil painting, 3D render), camera angle, lighting style (e.g., cinematic, volumetric), and color palette.\n",
    "* **Sentence 5:** Mention specific textures, clothing details, or unique stylistic flourishes.\n",
    "\n",
    "2.  **Tone & Style:**\n",
    "* Be objective and direct.\n",
    "* Use precise visual terminology (e.g., instead of \"cool clothes,\" say \"a distressed leather jacket with silver studs\").\n",
    "* Do NOT use filler phrases like \"This image shows,\" \"A picture of,\" or \"In this scene.\" Start directly with the subject.\n",
    "\n",
    "3.  **Detail Level:**\n",
    "* Describe texts or signs visible in the image if legible.\n",
    "* Describe the emotion or atmosphere if it is visually distinct (e.g., \"melancholic atmosphere,\" \"chaotic energy\").\n",
    "\n",
    "**Output Format:**\n",
    "Provide a single, flowing paragraph of text between 150-250 words.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8f731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/weishao/chojnowski.h/.conda/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 13/13 [00:26<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen3VLMoeForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen3-VL-30B-A3B-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = Qwen3VLMoeForConditionalGeneration.from_pretrained(\n",
    "    model_name, dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\", device_map=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91978e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"A breathtaking aerial view captures a vast, snow-dusted mountain range from the perspective of an airplane window, with the aircraft's wingtip visible in the foreground. The scene unfolds in layers, with a dense, white cloud bank filling the lower portion of the frame, creating a sense of immense altitude and separation from the earth below. Beyond the clouds, a rugged alpine landscape stretches into the distance, its peaks and ridges blanketed in snow and ice, their sharp silhouettes contrasting against a pale blue sky. The lighting is bright and diffuse, characteristic of high-altitude daylight, which casts soft shadows and emphasizes the textures of the snow and rock. The image is a high-fidelity photograph, captured from a high-angle perspective, likely during a flight over a major mountain range. The color palette is dominated by cool tones of white, blue, and grey, with subtle hints of dark earthy tones on the lower slopes. The overall atmosphere is one of serene grandeur and vast, untamed natural beauty.\"]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open('../data/tet.jpg')\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\", \n",
    "                \"image\": image\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\", \n",
    "                \"text\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "with torch.inference_mode():\n",
    "    generated_ids = model.generate(\n",
    "        **inputs, \n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.8,\n",
    "        top_k=20,\n",
    "        max_new_tokens=500,\n",
    "    )\n",
    "\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(output_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
